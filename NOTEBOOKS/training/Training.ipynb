{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below we can find the loss function of YOLOv3. Every part it's properly weighted to highlight network properties\n",
    "\n",
    "### XY Loss\n",
    "This loss penalize an incorrect centroid coordinates prediction. It's a sum of L2 distances\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&\\lambda_{coord} \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}[(x_i-\\hat{x}_i)^2 + (y_i-\\hat{y}_i)^2 ] \\, +\n",
    "\\end{align}\n",
    "$\n",
    "### HW Loss\n",
    "Calculate loss of the width and height: sum of L2 distances. We take the square root because we have to compensate the fact that bigger bounding boxes are prone to bigger errors.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&+ \\lambda_{coord} \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}[(\\sqrt{w_i}-\\sqrt{\\hat{w}_i})^2 +(\\sqrt{h_i}-\\sqrt{\\hat{h}_i})^2 ] \\, +\n",
    "\\end{align}\n",
    "$\n",
    "### Objectness Loss\n",
    "To penalize false detection: Weighted Binary Crossentropy\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&+ \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}(\\log\\hat{C}_{ij}) + \\lambda_{noobj}\\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{noobj}(\\log(1-\\hat{C}_{ij})) \\, + \n",
    "\\end{align}\n",
    "$\n",
    "### Class Loss\n",
    "To penalize the softmax prediction on the classes, only when there is actually something on that anchor box\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&+ \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}(p_i(c)\\cdot \\log\\hat{p}_i(c))\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Anchors\n",
    "yolo_anchors = np.array([(10, 10), (22, 23), (47, 33), (39, 81), (82, 54), (127, 86),\n",
    "                         (118, 168), (194, 130), (257, 221)], np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh_to_x1x2y1y2(box):\n",
    "    xy = box[..., 0:2]\n",
    "    wh = box[..., 2:4]\n",
    "\n",
    "    x1y1 = xy - wh / 2\n",
    "    x2y2 = xy + wh / 2\n",
    "\n",
    "    y_box = tf.concat([x1y1, x2y2], axis=-1)\n",
    "    return y_box\n",
    "\n",
    "\n",
    "def xywh_to_y1x1y2x2(box):\n",
    "    x = box[..., 0:1]\n",
    "    y = box[..., 1:2]\n",
    "    w = box[..., 2:3]\n",
    "    h = box[..., 3:4]\n",
    "\n",
    "    yx = tf.concat([y, x], axis=-1)\n",
    "    hw = tf.concat([h, w], axis=-1)\n",
    "\n",
    "    y1x1 = yx - hw / 2\n",
    "    y2x2 = yx + hw / 2\n",
    "\n",
    "    y_box = tf.concat([y1x1, y2x2], axis=-1)\n",
    "    return y_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(box_a, box_b):\n",
    "    \"\"\"\n",
    "    calculate iou between box_a and multiple box_b in a broadcast way.\n",
    "\n",
    "    inputs:\n",
    "    box_a: a tensor full of boxes, eg. (B, N, 4), box is in x1y1x2y2\n",
    "    box_b: another tensor full of boxes, eg. (B, M, 4)\n",
    "    \"\"\"\n",
    "\n",
    "    # (B, N, 1, 4)\n",
    "    box_a = tf.expand_dims(box_a, -2)\n",
    "    # (B, 1, M, 4)\n",
    "    box_b = tf.expand_dims(box_b, -3)\n",
    "    # (B, N, M, 4)\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_a), tf.shape(box_b))\n",
    "\n",
    "    # (B, N, M, 4)\n",
    "    # (B, N, M, 4)\n",
    "    box_a = tf.broadcast_to(box_a, new_shape)\n",
    "    box_b = tf.broadcast_to(box_b, new_shape)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    al, at, ar, ab = tf.split(box_a, 4, -1)\n",
    "    bl, bt, br, bb = tf.split(box_b, 4, -1)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    left = tf.math.maximum(al, bl)\n",
    "    right = tf.math.minimum(ar, br)\n",
    "    top = tf.math.maximum(at, bt)\n",
    "    bot = tf.math.minimum(ab, bb)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    iw = tf.clip_by_value(right - left, 0, 1)\n",
    "    ih = tf.clip_by_value(bot - top, 0, 1)\n",
    "    i = iw * ih\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    area_a = (ar - al) * (ab - at)\n",
    "    area_b = (br - bl) * (bb - bt)\n",
    "    union = area_a + area_b - i\n",
    "\n",
    "    # (B, N, M)\n",
    "    iou = tf.squeeze(i / (union + 1e-7), axis=-1)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode the output / Encode the input\n",
    "\n",
    "In the image below, we're gonna predict the $t_i$ values, but surely we need to decode the the actual values. \n",
    "\n",
    "\n",
    "<img src=\"img/output.png\" width=\"400\">\n",
    "\n",
    "In the original paper it uses different independent logistic classifiers because it may be trained in complex databases with overlapping labels. Since it's not out case we're gonna use a softmax with a cross-entropy loss (instead of binary-crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "The decoding functions are more or less adapted from different github repos. That doesn't means i copied them all, but surely i took inspiration from them because it's the most boring part since it's only a software implementation of trivial functions (once the mechanism it's understood).\n",
    "\n",
    "Still, it's no easy task. YOLO paper it's commonly known to be difficult to fully understand, and i saw a lot of errors even in StackExchange discussions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_into_abs(y_pred, valid_anchor, num_classes = 10):\n",
    "    \"\"\"\n",
    "    Given a cell offset prediction from the model, calculate the absolute box coordinates to the whole image.\n",
    "    note that, we divide w and h by grid size \n",
    "    INPUTS:\n",
    "    y_pred: Prediction tensor from the model output, in the shape of (batch, grid, grid, anchor, 5 + num_classes)\n",
    "    OUTPUTS:\n",
    "    y_box: boxes in shape of (batch, grid, grid, anchor, 4), the last dimension is (xmin, ymin, xmax, ymax)\n",
    "                                                                                #Seems like it's (x,y,w,h)\n",
    "    objectness: probability that an object exists\n",
    "    classes: probability of classes\n",
    "    \"\"\"\n",
    "    t_xy, t_wh, objectness, classes = tf.split(\n",
    "        y_pred, (2, 2, 1, num_classes), axis=-1)\n",
    "    \n",
    "    # That's because it's a Logistic classifier\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "#     classes = tf.sigmoid(classes)\n",
    "# we're not gonna sigmoid 'em because we're gonna use tf.nn.softmax_cross_entropy_with_logits\n",
    "    \n",
    "    grid_size = tf.shape(y_pred)[1]\n",
    "    \n",
    "##########################\n",
    "    \n",
    "    # Now i'm gonna get a tensor like this\n",
    "    #\n",
    "    # [[[[0, 0]], [[1, 0]], [[2, 0]]],\n",
    "    #  [[[0, 1]], [[1, 1]], [[2, 1]]],\n",
    "    #  [[[0, 2]], [[1, 2]], [[2, 2]]]]\n",
    "    #\n",
    "    # we have a grid, which can always give us (y, x)\n",
    "    # if we access grid[x][y]. For example, grid[0][1] == [[1, 0]]\n",
    "    \n",
    "    C_xy = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    C_xy = tf.stack(C_xy, axis=-1)\n",
    "    C_xy = tf.expand_dims(C_xy, axis=2)\n",
    "    \n",
    "##########################\n",
    "    \n",
    "    # bx = sigmoid(tx) + Cx\n",
    "    # by = sigmoid(ty) + Cy\n",
    "    #\n",
    "    # for example, if all elements in b_xy are (0.1, 0.2), the result will be\n",
    "    #\n",
    "    # [[[[0.1, 0.2]], [[1.1, 0.2]], [[2.1, 0.2]]],\n",
    "    #  [[[0.1, 1.2]], [[1.1, 1.2]], [[2.1, 1.2]]],\n",
    "    #  [[[0.1, 2.2]], [[1.1, 2.2]], [[2.1, 2.2]]]]\n",
    "    \n",
    "    b_xy = tf.sigmoid(t_xy) + tf.cast(C_xy, tf.float32)\n",
    "\n",
    "    # finally, divide this absolute box_xy by grid_size, and then we will get the normalized bbox centroids\n",
    "    # for each anchor in each grid cell. b_xy is now in shape (batch_size, grid_size, grid_size, num_anchor, 2)\n",
    "    #\n",
    "    # [[[[0.1/3, 0.2/3]], [[1.1/3, 0.2/3]], [[2.1/3, 0.2/3]]],\n",
    "    #  [[[0.1/3, 1.2/3]], [[1.1/3, 1.2]/3], [[2.1/3, 1.2/3]]],\n",
    "    #  [[[0.1/3, 2.2/3]], [[1.1/3, 2.2/3]], [[2.1/3, 2.2/3]]]]\n",
    "    #\n",
    "    b_xy = b_xy / tf.cast(grid_size, tf.float32)\n",
    "    \n",
    "##########################\n",
    "\n",
    "    # it does not make sense for the box to have a negative width or height. That’s why\n",
    "    # we take the exponent of the predicted number.\n",
    "    b_wh = tf.exp(t_wh) * valid_anchor\n",
    "    \n",
    "##########################\n",
    "\n",
    "    y_box = tf.concat([b_xy, b_wh], axis=-1)\n",
    "    return y_box, objectness, classes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_into_rel(y_true, valid_anchor):\n",
    "    \"\"\"\n",
    "    This is the inverse of `decode_into_abs` above. It's turning (bx, by, bw, bh) into\n",
    "    (tx, ty, tw, th) that is relative to cell location.\n",
    "    \"\"\"\n",
    "    grid_size = tf.shape(y_true)[1]\n",
    "    C_xy = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    C_xy = tf.expand_dims(tf.stack(C_xy, axis=-1), axis=2)\n",
    "\n",
    "    b_xy = y_true[..., 0:2]\n",
    "    b_wh = y_true[..., 2:4]\n",
    "    t_xy = b_xy * tf.cast(grid_size, tf.float32) - tf.cast(C_xy, tf.float32)\n",
    "\n",
    "    t_wh = tf.math.log(b_wh / valid_anchor)\n",
    "    # b_wh could have some cells are 0, divided by anchor could result in inf or nan\n",
    "    t_wh = tf.where(\n",
    "        tf.logical_or(tf.math.is_inf(t_wh), tf.math.is_nan(t_wh)),\n",
    "        tf.zeros_like(t_wh), t_wh)\n",
    "\n",
    "    y_box = tf.concat([t_xy, t_wh], axis=-1)\n",
    "    return y_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "Before starting with the loss function itself we need some utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryCrossentropy(pred_prob, labels):\n",
    "    # I use a custom crossentropy because i need to weight diffently the 2 parts\n",
    "    epsilon = 1e-7\n",
    "    pred_prob = tf.clip_by_value(pred_prob, epsilon, 1 - epsilon)\n",
    "    return -(labels * tf.math.log(pred_prob) +\n",
    "             (1 - labels) * tf.math.log(1 - pred_prob))\n",
    "\n",
    "class YoloLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, num_classes, valid_anchors_wh = yolo_anchors):\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_thresh = 0.5\n",
    "        self.valid_anchors_wh = valid_anchors_wh\n",
    "        self.lambda_coord = 5.0\n",
    "        self.lamda_noobj = 0.5\n",
    "    \n",
    "    def __call__(self, y_true, y_pred, sample_weight = None): # In order to call it like a function\n",
    "        \"\"\"\n",
    "        calculate the loss of model prediction for one scale\n",
    "        \"\"\"\n",
    "        # suffix rel (relative) means that its coordinates are relative to cells\n",
    "        # basically (tx, ty, tw, th) format from the paper\n",
    "        # _rel is used to calcuate the loss\n",
    "        # suffix abs (absolute) means that its coordinates are absolute with in whole image\n",
    "        # basically (bx, by, bw, bh) format from the paper\n",
    "        # _abs is used to calcuate iou and ignore mask\n",
    "\n",
    "######### sort of \"Non Max Suppression\" to get an ignore mask, we need the absolute values!\n",
    "\n",
    "        # this box is used to calculate IoU, NOT loss. \n",
    "        # pred_xy_abs: (batch, grid, grid, anchor, 2)\n",
    "        # pred_wh_abs: (batch, grid, grid, anchor, 2)\n",
    "        # pred_obj: (batch, grid, grid, anchor, 1)\n",
    "        # pred_class: (batch, grid, grid, anchor, num_classes)\n",
    "        pred_box_abs, pred_obj, pred_class = decode_into_abs(\n",
    "            y_pred, self.valid_anchors_wh, self.num_classes)\n",
    "        pred_box_abs = xywh_to_x1x2y1y2(pred_box_abs)\n",
    "\n",
    "        # split y_true into xy, wh, objectness and one-hot classes\n",
    "        # pred_xy_abs: (batch, grid, grid, anchor, 2)\n",
    "        # pred_wh_abs: (batch, grid, grid, anchor, 2)\n",
    "        # pred_obj: (batch, grid, grid, anchor, 1)\n",
    "        # pred_class: (batch, grid, grid, anchor, num_classes)\n",
    "        true_xy_abs, true_wh_abs, true_obj, true_class = tf.split(\n",
    "            y_true, (2, 2, 1, self.num_classes), axis=-1)\n",
    "        true_box_abs = tf.concat([true_xy_abs, true_wh_abs], axis=-1)\n",
    "        true_box_abs = xywh_to_x1x2y1y2(true_box_abs)\n",
    "\n",
    "            # use the absolute yolo box to calculate iou and ignore mask\n",
    "        ignore_mask = self.nonmax_mask(true_obj, true_box_abs,\n",
    "                                            pred_box_abs)\n",
    "        \n",
    "######### Getting properly formatted values to process the loss functions    \n",
    "    \n",
    "        # true_box_rel: (batch, grid, grid, anchor, 4)\n",
    "        true_box_rel = get_relative_yolo_box(y_true, self.valid_anchors_wh)\n",
    "        true_xy_rel = true_box_rel[..., 0:2]\n",
    "        true_wh_rel = true_box_rel[..., 2:4]\n",
    "\n",
    "        # some adjustment to improve small box detection, note the (2-truth.w*truth.h) below\n",
    "        weight = 2 - true_wh_abs[..., 0] * true_wh_abs[..., 1]\n",
    "\n",
    "        # YoloV2:\n",
    "        # \"If the cell is offset from the top left corner of the image by (cx , cy)\n",
    "        # and the bounding box prior has width and height pw , ph , then the predictions correspond to:\"\n",
    "        #\n",
    "        # to calculate the iou and determine the ignore mask, we need to first transform\n",
    "        # prediction into real coordinates (bx, by, bw, bh)\n",
    "\n",
    "        \n",
    "        # split y_pred into xy, wh, objectness and one-hot classes\n",
    "        # pred_??_rel: (batch, grid, grid, anchor, 2)\n",
    "        # We have to use a sigmoid function because x,y have to be values between 0 and 1\n",
    "        # cause they are realtive position INSIDE the single cell\n",
    "        pred_xy_rel = tf.sigmoid(y_pred[..., 0:2])\n",
    "        pred_wh_rel = y_pred[..., 2:4]\n",
    "        \n",
    "        # YoloV2:\n",
    "        # \"This ground truth value can be easily computed by inverting the equations above.\"\n",
    "        #\n",
    "        # to calculate loss and differentiation, we need to transform ground truth into\n",
    "        # cell offset first like demonstrated here:\n",
    "        # https://github.com/pjreddie/darknet/blob/f6d861736038da22c9eb0739dca84003c5a5e275/src/yolo_layer.c#L93\n",
    "        xy_loss = self.calc_xy_loss(true_obj, true_xy_rel, pred_xy_rel, weight)\n",
    "        wh_loss = self.calc_wh_loss(true_obj, true_wh_rel, pred_wh_rel, weight)\n",
    "        class_loss = self.calc_class_loss(true_obj, true_class, pred_class)\n",
    "\n",
    "\n",
    "        obj_loss = self.calc_obj_loss(true_obj, pred_obj, ignore_mask)\n",
    "\n",
    "        # YoloV1: Function (3)\n",
    "        return xy_loss + wh_loss + class_loss + obj_loss #, (xy_loss, wh_loss,\n",
    "                                                          # class_loss,\n",
    "                                                          # obj_loss)\n",
    "    \n",
    "    def nonmax_mask(self, true_obj, true_box, pred_box):\n",
    "        # YOLOv3:\n",
    "        # \"If the bounding box prior is not the best but does overlap a ground\n",
    "        # truth object by more than some threshold we ignore the prediction.\n",
    "        # We use the threshold of .5.\"\n",
    "        # calculate the iou for each pair of pred bbox and true bbox, then find the best among them\n",
    "        # we will ignore them in the object loss\n",
    "\n",
    "        # (None, 13, 13, 3, 4)\n",
    "        true_box_shape = tf.shape(true_box)\n",
    "        # (None, 13, 13, 3, 4)\n",
    "        pred_box_shape = tf.shape(pred_box)\n",
    "        # (None, 507, 4)\n",
    "        true_box = tf.reshape(true_box, [true_box_shape[0], -1, 4])\n",
    "        # sort true_box to have non-zero boxes rank first\n",
    "        true_box = tf.sort(true_box, axis=1, direction=\"DESCENDING\")\n",
    "        \n",
    "        # (None, 70, 4)\n",
    "        # only use maximum 70 boxes per groundtruth to calcualte IOU, otherwise\n",
    "        # GPU emory comsumption would explode for a matrix like (16, 52*52*3, 52*52*3, 4)\n",
    "        true_box = true_box[:, 0:70, :]\n",
    "        # (None, 507, 4)\n",
    "        pred_box = tf.reshape(pred_box, [pred_box_shape[0], -1, 4])\n",
    "\n",
    "        # (None, 507, 507) for every BB prediction (13x13x3) it calculates its IoU over the ground truth\n",
    "        iou = broadcast_iou(pred_box, true_box)\n",
    "        # (None, 507) for every BB prediction (13x13x3) it keeps the best IoU over ground truth\n",
    "        best_iou = tf.reduce_max(iou, axis=-1)\n",
    "        # (None, 13, 13, 3)\n",
    "        best_iou = tf.reshape(best_iou, [pred_box_shape[0], pred_box_shape[1], pred_box_shape[2], pred_box_shape[3]])\n",
    "        # ignore_mask = 1 => don't ignore\n",
    "        # ignore_mask = 0 => should ignore\n",
    "        ignore_mask = tf.cast(best_iou < self.ignore_thresh, tf.float32)\n",
    "        # (None, 13, 13, 3, 1)\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, axis=-1)\n",
    "        return ignore_mask\n",
    "    \n",
    "    def calc_obj_loss(self, true_obj, pred_obj, ignore_mask):\n",
    "        \"\"\"\n",
    "        calculate loss of objectness: crossentropy\n",
    "        inputs:\n",
    "        true_obj: objectness from ground truth in shape of (batch, grid, grid, anchor, 1)\n",
    "        pred_obj: objectness from model prediction in shape of (batch, grid, grid, anchor, 1)\n",
    "        outputs:\n",
    "        obj_loss: objectness loss\n",
    "        \"\"\"\n",
    "\n",
    "        obj_entropy = BinaryCrossentropy(pred_obj, true_obj)\n",
    "\n",
    "        obj_loss = true_obj * obj_entropy\n",
    "        noobj_loss = (1 - true_obj) * obj_entropy * ignore_mask\n",
    "\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3, 4))\n",
    "        noobj_loss = tf.reduce_sum(\n",
    "            noobj_loss, axis=(1, 2, 3, 4)) * self.lamda_noobj\n",
    "\n",
    "        return obj_loss + noobj_loss\n",
    "\n",
    "\n",
    "    def calc_class_loss(self, true_obj, true_class, pred_class):\n",
    "        \"\"\"\n",
    "        calculate loss of class prediction\n",
    "        inputs:\n",
    "        true_obj: if the object present from ground truth in shape of (batch, grid, grid, anchor, 1)\n",
    "        true_class: one-hot class from ground truth in shape of (batch, grid, grid, anchor, num_classes)\n",
    "        pred_class: one-hot class from model prediction in shape of (batch, grid, grid, anchor, num_classes)\n",
    "        outputs:\n",
    "        class_loss: class loss\n",
    "        \"\"\"\n",
    "        # Yolov1:\n",
    "        # \"Note that the loss function only penalizes classiﬁcation error\n",
    "        # if an object is present in that grid cell (hence the conditional\n",
    "        # class probability discussed earlier).\"\n",
    "        class_loss = tf.nn.softmax_cross_entropy_with_logits(true_class, pred_class, axis=-1)\n",
    "        class_loss = true_obj * class_loss\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3, 4))\n",
    "        return class_loss\n",
    "    \n",
    "    def calc_xy_loss(self, true_obj, true_xy, pred_xy, weight):\n",
    "        \"\"\"\n",
    "        calculate loss of the centroid coordinate: sum of L2 distances\n",
    "        inputs:\n",
    "        true_obj: if the object present from ground truth in shape of (batch, grid, grid, anchor, 1)\n",
    "        true_xy: centroid x and y from ground truth in shape of (batch, grid, grid, anchor, 2)\n",
    "        pred_xy: centroid x and y from model prediction in shape of (batch, grid, grid, anchor, 2)\n",
    "        weight: weight adjustment, reward smaller bounding box\n",
    "        outputs:\n",
    "        xy_loss: centroid loss\n",
    "        \"\"\"\n",
    "        # shape (batch, grid, grid, anchor), eg. (32, 13, 13, 3)\n",
    "        xy_loss = tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "\n",
    "        # in order to element-wise multiply the result from tf.reduce_sum\n",
    "        # we need to squeeze one dimension for objectness here\n",
    "        true_obj = tf.squeeze(true_obj, axis=-1)\n",
    "\n",
    "        # YoloV1:\n",
    "        # \"It also only penalizes bounding box coordinate error if that\n",
    "        # predictor is \"responsible\" for the ground truth box (i.e. has the\n",
    "        # highest IOU of any predictor in that grid cell).\"\n",
    "        xy_loss = true_obj * xy_loss * weight\n",
    "\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3)) * self.lambda_coord\n",
    "\n",
    "        return xy_loss\n",
    "\n",
    "    def calc_wh_loss(self, true_obj, true_wh, pred_wh, weight):\n",
    "        \"\"\"\n",
    "        calculate loss of the width and height: sum of L2 distances\n",
    "        inputs:\n",
    "        true_obj: if the object present from ground truth in shape of (batch, grid, grid, anchor, 1)\n",
    "        true_wh: width and height from ground truth in shape of (batch, grid, grid, anchor, 2)\n",
    "        pred_wh: width and height from model prediction in shape of (batch, grid, grid, anchor, 2)\n",
    "        weight: weight adjustment, reward smaller bounding box\n",
    "        outputs:\n",
    "        wh_loss: width and height loss\n",
    "        \"\"\"\n",
    "        # shape (batch, grid, grid, anchor), eg. (32, 13, 13, 3)\n",
    "        wh_loss = tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        true_obj = tf.squeeze(true_obj, axis=-1)\n",
    "        wh_loss = true_obj * wh_loss * weight\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3)) * self.lambda_coord\n",
    "        return wh_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Seems like we're erady for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/andrea/AI/ispr_yolo/data')\n",
    "\n",
    "import DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k/train'+ '/*.jpg'\n",
    "train_ds = DataPreprocessing.create_dataset(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:748 train_step\n        loss = self.compiled_loss(\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    <ipython-input-22-2f29e9543fa7>:34 __call__\n        pred_box_abs, pred_obj, pred_class = decode_into_abs(\n    <ipython-input-6-0866ff899f95>:64 decode_into_abs\n        b_wh = tf.exp(t_wh) * valid_anchor\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1136 binary_op_wrapper\n        out = r_op(x)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:845 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (Exp:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e7bd4fc4fff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0myolo_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYoloLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myolo_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myolo_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nadam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:748 train_step\n        loss = self.compiled_loss(\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    <ipython-input-22-2f29e9543fa7>:34 __call__\n        pred_box_abs, pred_obj, pred_class = decode_into_abs(\n    <ipython-input-6-0866ff899f95>:64 decode_into_abs\n        b_wh = tf.exp(t_wh) * valid_anchor\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1136 binary_op_wrapper\n        out = r_op(x)\n    /home/andrea/anaconda2/envs/ai/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:845 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (Exp:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "yolo_loss = YoloLoss(10, yolo_anchors)\n",
    "yolo.compile(loss=yolo_loss, optimizer='nadam')\n",
    "yolo.fit(train_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
