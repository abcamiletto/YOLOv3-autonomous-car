{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below we can find the loss function of YOLOv3. Every part it's properly weighted to highlight network properties\n",
    "\n",
    "### XY Loss\n",
    "This loss penalize an incorrect centroid coordinates prediction. It's a sum of L2 distances\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&\\lambda_{coord} \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}[(x_i-\\hat{x}_i)^2 + (y_i-\\hat{y}_i)^2 ] \\, +\n",
    "\\end{align}\n",
    "$\n",
    "### HW Loss\n",
    "Calculate loss of the width and height: sum of L2 distances. We take the square root because we have to compensate the fact that bigger bounding boxes are prone to bigger errors.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&+ \\lambda_{coord} \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}[(\\sqrt{w_i}-\\sqrt{\\hat{w}_i})^2 +(\\sqrt{h_i}-\\sqrt{\\hat{h}_i})^2 ] \\, +\n",
    "\\end{align}\n",
    "$\n",
    "### Objectness Loss\n",
    "To penalize false detection: Weighted Binary Crossentropy\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&+ \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}(\\log\\hat{C}_{ij}) + \\lambda_{noobj}\\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{noobj}(\\log(1-\\hat{C}_{ij})) \\, + \n",
    "\\end{align}\n",
    "$\n",
    "### Class Loss\n",
    "To penalize the softmax prediction on the classes, only when there is actually something on that anchor box\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&+ \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}(p_i(c)\\cdot \\log\\hat{p}_i(c))\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Anchors\n",
    "yolo_anchors_tf = tf.constant([(10, 10), (22, 23), (47, 33), (39, 81), (82, 54), (127, 86),\n",
    "                         (118, 168), (194, 130), (257, 221)], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh_to_x1x2y1y2(box):\n",
    "    xy = box[..., 0:2]\n",
    "    wh = box[..., 2:4]\n",
    "\n",
    "    x1y1 = xy - wh / 2\n",
    "    x2y2 = xy + wh / 2\n",
    "\n",
    "    y_box = tf.concat([x1y1, x2y2], axis=-1)\n",
    "    return y_box\n",
    "\n",
    "\n",
    "def xywh_to_y1x1y2x2(box):\n",
    "    x = box[..., 0:1]\n",
    "    y = box[..., 1:2]\n",
    "    w = box[..., 2:3]\n",
    "    h = box[..., 3:4]\n",
    "\n",
    "    yx = tf.concat([y, x], axis=-1)\n",
    "    hw = tf.concat([h, w], axis=-1)\n",
    "\n",
    "    y1x1 = yx - hw / 2\n",
    "    y2x2 = yx + hw / 2\n",
    "\n",
    "    y_box = tf.concat([y1x1, y2x2], axis=-1)\n",
    "    return y_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(box_a, box_b):\n",
    "    \"\"\"\n",
    "    calculate iou between box_a and multiple box_b in a broadcast way.\n",
    "\n",
    "    inputs:\n",
    "    box_a: a tensor full of boxes, eg. (B, N, 4), box is in x1y1x2y2\n",
    "    box_b: another tensor full of boxes, eg. (B, M, 4)\n",
    "    \"\"\"\n",
    "\n",
    "    # (B, N, 1, 4)\n",
    "    box_a = tf.expand_dims(box_a, -2)\n",
    "    # (B, 1, M, 4)\n",
    "    box_b = tf.expand_dims(box_b, -3)\n",
    "    # (B, N, M, 4)\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_a), tf.shape(box_b))\n",
    "\n",
    "    # (B, N, M, 4)\n",
    "    # (B, N, M, 4)\n",
    "    box_a = tf.broadcast_to(box_a, new_shape)\n",
    "    box_b = tf.broadcast_to(box_b, new_shape)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    al, at, ar, ab = tf.split(box_a, 4, -1)\n",
    "    bl, bt, br, bb = tf.split(box_b, 4, -1)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    left = tf.math.maximum(al, bl)\n",
    "    right = tf.math.minimum(ar, br)\n",
    "    top = tf.math.maximum(at, bt)\n",
    "    bot = tf.math.minimum(ab, bb)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    iw = tf.clip_by_value(right - left, 0, 1)\n",
    "    ih = tf.clip_by_value(bot - top, 0, 1)\n",
    "    i = iw * ih\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    area_a = (ar - al) * (ab - at)\n",
    "    area_b = (br - bl) * (bb - bt)\n",
    "    union = area_a + area_b - i\n",
    "\n",
    "    # (B, N, M)\n",
    "    iou = tf.squeeze(i / (union + 1e-7), axis=-1)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode the output / Encode the input\n",
    "\n",
    "In the image below, we're gonna predict the $t_i$ values, but surely we need to decode the the actual values. \n",
    "\n",
    "\n",
    "<img src=\"img/output.png\" width=\"400\">\n",
    "\n",
    "In the original paper it uses different independent logistic classifiers because it may be trained in complex databases with overlapping labels. Since it's not out case we're gonna use a softmax with a cross-entropy loss (instead of binary-crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "The decoding functions are more or less adapted from different github repos. That doesn't means i copied them all, but surely i took inspiration from them because it's the most boring part since it's only a software implementation of trivial functions (once the mechanism it's understood).\n",
    "\n",
    "Still, it's no easy task. YOLO paper it's commonly known to be difficult to fully understand, and i saw a lot of errors even in StackExchange discussions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_into_abs(y_pred, valid_anchor, num_classes = 10):\n",
    "    \"\"\"\n",
    "    Given a cell offset prediction from the model, calculate the absolute box coordinates to the whole image.\n",
    "    note that, we divide w and h by grid size \n",
    "    INPUTS:\n",
    "    y_pred: Prediction tensor from the model output, in the shape of (batch, grid, grid, anchor, 5 + num_classes)\n",
    "    OUTPUTS:\n",
    "    y_box: boxes in shape of (batch, grid, grid, anchor, 4), the last dimension is (xmin, ymin, xmax, ymax)\n",
    "                                                                                #Seems like it's (x,y,w,h)\n",
    "    objectness: probability that an object exists\n",
    "    classes: probability of classes\n",
    "    \"\"\"\n",
    "    t_xy, t_wh, objectness, classes = tf.split(\n",
    "        y_pred, (2, 2, 1, num_classes), axis=-1)\n",
    "    \n",
    "    # That's because it's a Logistic classifier\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    classes = tf.sigmoid(classes)\n",
    "# we're not gonna sigmoid 'em because we're gonna use tf.nn.softmax_cross_entropy_with_logits\n",
    "    \n",
    "    grid_size = tf.shape(y_pred)[1]\n",
    "    \n",
    "##########################\n",
    "    \n",
    "    # Now i'm gonna get a tensor like this\n",
    "    #\n",
    "    # [[[[0, 0]], [[1, 0]], [[2, 0]]],\n",
    "    #  [[[0, 1]], [[1, 1]], [[2, 1]]],\n",
    "    #  [[[0, 2]], [[1, 2]], [[2, 2]]]]\n",
    "    #\n",
    "    # we have a grid, which can always give us (y, x)\n",
    "    # if we access grid[x][y]. For example, grid[0][1] == [[1, 0]]\n",
    "    \n",
    "    C_xy = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    C_xy = tf.stack(C_xy, axis=-1)\n",
    "    C_xy = tf.expand_dims(C_xy, axis=2)\n",
    "    \n",
    "##########################\n",
    "    \n",
    "    # bx = sigmoid(tx) + Cx\n",
    "    # by = sigmoid(ty) + Cy\n",
    "    #\n",
    "    # for example, if all elements in b_xy are (0.1, 0.2), the result will be\n",
    "    #\n",
    "    # [[[[0.1, 0.2]], [[1.1, 0.2]], [[2.1, 0.2]]],\n",
    "    #  [[[0.1, 1.2]], [[1.1, 1.2]], [[2.1, 1.2]]],\n",
    "    #  [[[0.1, 2.2]], [[1.1, 2.2]], [[2.1, 2.2]]]]\n",
    "    \n",
    "    b_xy = tf.sigmoid(t_xy) + tf.cast(C_xy, tf.float32)\n",
    "\n",
    "    # finally, divide this absolute box_xy by grid_size, and then we will get the normalized bbox centroids\n",
    "    # for each anchor in each grid cell. b_xy is now in shape (batch_size, grid_size, grid_size, num_anchor, 2)\n",
    "    #\n",
    "    # [[[[0.1/3, 0.2/3]], [[1.1/3, 0.2/3]], [[2.1/3, 0.2/3]]],\n",
    "    #  [[[0.1/3, 1.2/3]], [[1.1/3, 1.2]/3], [[2.1/3, 1.2/3]]],\n",
    "    #  [[[0.1/3, 2.2/3]], [[1.1/3, 2.2/3]], [[2.1/3, 2.2/3]]]]\n",
    "    #\n",
    "    b_xy = b_xy / tf.cast(grid_size, tf.float32)\n",
    "    \n",
    "##########################\n",
    "\n",
    "    # it does not make sense for the box to have a negative width or height. That’s why\n",
    "    # we take the exponent of the predicted number.\n",
    "    b_wh = tf.exp(t_wh) * valid_anchor\n",
    "    \n",
    "##########################\n",
    "\n",
    "    y_box = tf.concat([b_xy, b_wh], axis=-1)\n",
    "    return y_box, objectness, classes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_into_rel(y_true, valid_anchor):\n",
    "    \"\"\"\n",
    "    This is the inverse of `decode_into_abs` above. It's turning (bx, by, bw, bh) into\n",
    "    (tx, ty, tw, th) that is relative to cell location.\n",
    "    \"\"\"\n",
    "    grid_size = tf.shape(y_true)[1]\n",
    "    C_xy = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    C_xy = tf.expand_dims(tf.stack(C_xy, axis=-1), axis=2)\n",
    "\n",
    "    b_xy = y_true[..., 0:2]\n",
    "    b_wh = y_true[..., 2:4]\n",
    "    t_xy = b_xy * tf.cast(grid_size, tf.float32) - tf.cast(C_xy, tf.float32)\n",
    "\n",
    "    t_wh = tf.math.log(b_wh / valid_anchor)\n",
    "    # b_wh could have some cells are 0, divided by anchor could result in inf or nan\n",
    "    t_wh = tf.where(\n",
    "        tf.logical_or(tf.math.is_inf(t_wh), tf.math.is_nan(t_wh)),\n",
    "        tf.zeros_like(t_wh), t_wh)\n",
    "\n",
    "    y_box = tf.concat([t_xy, t_wh], axis=-1)\n",
    "    return y_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "Before starting with the loss function itself we need some utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c9e63e7cc3e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m              (1 - labels) * tf.math.log(1 - pred_prob))\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mYoloLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_anchors_wh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_anchors_tf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "def BinaryCrossentropy(pred_prob, labels):\n",
    "    # I use a custom crossentropy because i need to weight diffently the 2 parts\n",
    "    epsilon = 1e-7\n",
    "    pred_prob = tf.clip_by_value(pred_prob, epsilon, 1 - epsilon)\n",
    "    return -(labels * tf.math.log(pred_prob) +\n",
    "             (1 - labels) * tf.math.log(1 - pred_prob))\n",
    "\n",
    "class YoloLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, num_classes, valid_anchors_wh = yolo_anchors_tf[6:9], **kwargs):\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_thresh = 0.5\n",
    "        self.valid_anchors_wh = valid_anchors_wh\n",
    "        self.lambda_coord = 5.0\n",
    "        self.lamda_noobj = 0.5\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def __call__(self, y_true, y_pred, sample_weight = None): # In order to call it like a function\n",
    "        \"\"\"\n",
    "        calculate the loss of model prediction for one scale\n",
    "        \"\"\"\n",
    "        # suffix rel (relative) means that its coordinates are relative to cells\n",
    "        # basically (tx, ty, tw, th) format from the paper\n",
    "        # _rel is used to calcuate the loss\n",
    "        # suffix abs (absolute) means that its coordinates are absolute with in whole image\n",
    "        # basically (bx, by, bw, bh) format from the paper\n",
    "        # _abs is used to calcuate iou and ignore mask\n",
    "\n",
    "######### sort of \"Non Max Suppression\" to get an ignore mask, we need the absolute values!\n",
    "\n",
    "        # this box is used to calculate IoU, NOT loss. \n",
    "        # pred_xy_abs: (batch, grid, grid, anchor, 2)\n",
    "        # pred_wh_abs: (batch, grid, grid, anchor, 2)\n",
    "        # pred_obj: (batch, grid, grid, anchor, 1)\n",
    "        # pred_class: (batch, grid, grid, anchor, num_classes)\n",
    "        pred_box_abs, pred_obj, pred_class = decode_into_abs(\n",
    "            y_pred, self.valid_anchors_wh, self.num_classes)\n",
    "        pred_box_abs = xywh_to_x1x2y1y2(pred_box_abs)\n",
    "\n",
    "        # split y_true into xy, wh, objectness and one-hot classes\n",
    "        # pred_xy_abs: (batch, grid, grid, anchor, 2)\n",
    "        # pred_wh_abs: (batch, grid, grid, anchor, 2)\n",
    "        # pred_obj: (batch, grid, grid, anchor, 1)\n",
    "        # pred_class: (batch, grid, grid, anchor, num_classes)\n",
    "        true_xy_abs, true_wh_abs, true_obj, true_class = tf.split(\n",
    "            y_true, (2, 2, 1, self.num_classes), axis=-1)\n",
    "        true_box_abs = tf.concat([true_xy_abs, true_wh_abs], axis=-1)\n",
    "        true_box_abs = xywh_to_x1x2y1y2(true_box_abs)\n",
    "\n",
    "            # use the absolute yolo box to calculate iou and ignore mask\n",
    "        ignore_mask = self.nonmax_mask(true_obj, true_box_abs,\n",
    "                                            pred_box_abs)\n",
    "        \n",
    "######### Getting properly formatted values to process the loss functions    \n",
    "    \n",
    "        # true_box_rel: (batch, grid, grid, anchor, 4)\n",
    "        true_box_rel = encode_into_rel(y_true, self.valid_anchors_wh)\n",
    "        true_xy_rel = true_box_rel[..., 0:2]\n",
    "        true_wh_rel = true_box_rel[..., 2:4]\n",
    "\n",
    "        # some adjustment to improve small box detection, note the (2-truth.w*truth.h) below\n",
    "        weight = 2 - true_wh_abs[..., 0] * true_wh_abs[..., 1]\n",
    "\n",
    "        # YoloV2:\n",
    "        # \"If the cell is offset from the top left corner of the image by (cx , cy)\n",
    "        # and the bounding box prior has width and height pw , ph , then the predictions correspond to:\"\n",
    "        #\n",
    "        # to calculate the iou and determine the ignore mask, we need to first transform\n",
    "        # prediction into real coordinates (bx, by, bw, bh)\n",
    "\n",
    "        \n",
    "        # split y_pred into xy, wh, objectness and one-hot classes\n",
    "        # pred_??_rel: (batch, grid, grid, anchor, 2)\n",
    "        # We have to use a sigmoid function because x,y have to be values between 0 and 1\n",
    "        # cause they are realtive position INSIDE the single cell\n",
    "        pred_xy_rel = tf.sigmoid(y_pred[..., 0:2])\n",
    "        pred_wh_rel = y_pred[..., 2:4]\n",
    "        \n",
    "        # YoloV2:\n",
    "        # \"This ground truth value can be easily computed by inverting the equations above.\"\n",
    "        #\n",
    "        # to calculate loss and differentiation, we need to transform ground truth into\n",
    "        # cell offset first like demonstrated here:\n",
    "        # https://github.com/pjreddie/darknet/blob/f6d861736038da22c9eb0739dca84003c5a5e275/src/yolo_layer.c#L93\n",
    "        xy_loss = self.calc_xy_loss(true_obj, true_xy_rel, pred_xy_rel, weight)\n",
    "        wh_loss = self.calc_wh_loss(true_obj, true_wh_rel, pred_wh_rel, weight)\n",
    "        class_loss = self.calc_class_loss(true_obj, true_class, pred_class)\n",
    "\n",
    "\n",
    "        obj_loss = self.calc_obj_loss(true_obj, pred_obj, ignore_mask)\n",
    "\n",
    "        # YoloV1: Function (3)\n",
    "        return xy_loss + wh_loss + class_loss + obj_loss #, (xy_loss, wh_loss,\n",
    "                                                          # class_loss,\n",
    "                                                          # obj_loss)\n",
    "    \n",
    "    def nonmax_mask(self, true_obj, true_box, pred_box):\n",
    "        # YOLOv3:\n",
    "        # \"If the bounding box prior is not the best but does overlap a ground\n",
    "        # truth object by more than some threshold we ignore the prediction.\n",
    "        # We use the threshold of .5.\"\n",
    "        # calculate the iou for each pair of pred bbox and true bbox, then find the best among them\n",
    "        # we will ignore them in the object loss\n",
    "\n",
    "        # (None, 13, 13, 3, 4)\n",
    "        true_box_shape = tf.shape(true_box)\n",
    "        # (None, 13, 13, 3, 4)\n",
    "        pred_box_shape = tf.shape(pred_box)\n",
    "        # (None, 507, 4)\n",
    "        true_box = tf.reshape(true_box, [true_box_shape[0], -1, 4])\n",
    "        # sort true_box to have non-zero boxes rank first\n",
    "        true_box = tf.sort(true_box, axis=1, direction=\"DESCENDING\")\n",
    "        \n",
    "        # (None, 70, 4)\n",
    "        # only use maximum 70 boxes per groundtruth to calcualte IOU, otherwise\n",
    "        # GPU emory comsumption would explode for a matrix like (16, 52*52*3, 52*52*3, 4)\n",
    "        true_box = true_box[:, 0:70, :]\n",
    "        # (None, 507, 4)\n",
    "        pred_box = tf.reshape(pred_box, [pred_box_shape[0], -1, 4])\n",
    "\n",
    "        # (None, 507, 507) for every BB prediction (13x13x3) it calculates its IoU over the ground truth\n",
    "        iou = broadcast_iou(pred_box, true_box)\n",
    "        # (None, 507) for every BB prediction (13x13x3) it keeps the best IoU over ground truth\n",
    "        best_iou = tf.reduce_max(iou, axis=-1)\n",
    "        # (None, 13, 13, 3)\n",
    "        best_iou = tf.reshape(best_iou, [pred_box_shape[0], pred_box_shape[1], pred_box_shape[2], pred_box_shape[3]])\n",
    "        # ignore_mask = 1 => don't ignore\n",
    "        # ignore_mask = 0 => should ignore\n",
    "        ignore_mask = tf.cast(best_iou < self.ignore_thresh, tf.float32)\n",
    "        # (None, 13, 13, 3, 1)\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, axis=-1)\n",
    "        return ignore_mask\n",
    "    \n",
    "    def calc_obj_loss(self, true_obj, pred_obj, ignore_mask):\n",
    "        \"\"\"\n",
    "        calculate loss of objectness: crossentropy\n",
    "        inputs:\n",
    "        true_obj: objectness from ground truth in shape of (batch, grid, grid, anchor, 1)\n",
    "        pred_obj: objectness from model prediction in shape of (batch, grid, grid, anchor, 1)\n",
    "        outputs:\n",
    "        obj_loss: objectness loss\n",
    "        \"\"\"\n",
    "\n",
    "        obj_entropy = BinaryCrossentropy(pred_obj, true_obj)\n",
    "\n",
    "        obj_loss = true_obj * obj_entropy\n",
    "        noobj_loss = (1 - true_obj) * obj_entropy * ignore_mask\n",
    "\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3, 4))\n",
    "        noobj_loss = tf.reduce_sum(\n",
    "            noobj_loss, axis=(1, 2, 3, 4)) * self.lamda_noobj\n",
    "\n",
    "        return obj_loss + noobj_loss\n",
    "\n",
    "\n",
    "    def calc_class_loss(self, true_obj, true_class, pred_class):\n",
    "        \"\"\"\n",
    "        calculate loss of class prediction\n",
    "        inputs:\n",
    "        true_obj: if the object present from ground truth in shape of (batch, grid, grid, anchor, 1)\n",
    "        true_class: one-hot class from ground truth in shape of (batch, grid, grid, anchor, num_classes)\n",
    "        pred_class: one-hot class from model prediction in shape of (batch, grid, grid, anchor, num_classes)\n",
    "        outputs:\n",
    "        class_loss: class loss\n",
    "        \"\"\"\n",
    "        # Yolov1:\n",
    "        # \"Note that the loss function only penalizes classiﬁcation error\n",
    "        # if an object is present in that grid cell (hence the conditional\n",
    "        # class probability discussed earlier).\"\n",
    "        class_loss = BinaryCrossentropy(true_class, pred_class)\n",
    "        class_loss = true_obj * class_loss\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3, 4))\n",
    "        return class_loss\n",
    "    \n",
    "    def calc_xy_loss(self, true_obj, true_xy, pred_xy, weight):\n",
    "        \"\"\"\n",
    "        calculate loss of the centroid coordinate: sum of L2 distances\n",
    "        inputs:\n",
    "        true_obj: if the object present from ground truth in shape of (batch, grid, grid, anchor, 1)\n",
    "        true_xy: centroid x and y from ground truth in shape of (batch, grid, grid, anchor, 2)\n",
    "        pred_xy: centroid x and y from model prediction in shape of (batch, grid, grid, anchor, 2)\n",
    "        weight: weight adjustment, reward smaller bounding box\n",
    "        outputs:\n",
    "        xy_loss: centroid loss\n",
    "        \"\"\"\n",
    "        # shape (batch, grid, grid, anchor), eg. (32, 13, 13, 3)\n",
    "        xy_loss = tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "\n",
    "        # in order to element-wise multiply the result from tf.reduce_sum\n",
    "        # we need to squeeze one dimension for objectness here\n",
    "        true_obj = tf.squeeze(true_obj, axis=-1)\n",
    "\n",
    "        # YoloV1:\n",
    "        # \"It also only penalizes bounding box coordinate error if that\n",
    "        # predictor is \"responsible\" for the ground truth box (i.e. has the\n",
    "        # highest IOU of any predictor in that grid cell).\"\n",
    "        xy_loss = true_obj * xy_loss * weight\n",
    "\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3)) * self.lambda_coord\n",
    "\n",
    "        return xy_loss\n",
    "\n",
    "    def calc_wh_loss(self, true_obj, true_wh, pred_wh, weight):\n",
    "        \"\"\"\n",
    "        calculate loss of the width and height: sum of L2 distances\n",
    "        inputs:\n",
    "        true_obj: if the object present from ground truth in shape of (batch, grid, grid, anchor, 1)\n",
    "        true_wh: width and height from ground truth in shape of (batch, grid, grid, anchor, 2)\n",
    "        pred_wh: width and height from model prediction in shape of (batch, grid, grid, anchor, 2)\n",
    "        weight: weight adjustment, reward smaller bounding box\n",
    "        outputs:\n",
    "        wh_loss: width and height loss\n",
    "        \"\"\"\n",
    "        # shape (batch, grid, grid, anchor), eg. (32, 13, 13, 3)\n",
    "        wh_loss = tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        true_obj = tf.squeeze(true_obj, axis=-1)\n",
    "        wh_loss = true_obj * wh_loss * weight\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3)) * self.lambda_coord\n",
    "        return wh_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/andrea/AI/ispr_yolo/data')\n",
    "\n",
    "from DataPreprocessing import generate_two_label_example\n",
    "\n",
    "label1, label2 = generate_two_label_example()\n",
    "label1 = tf.expand_dims(label1, axis = 0)\n",
    "label2 = tf.expand_dims(label2, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      "  [[[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      "  [[[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      "  [[[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      "  [[[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]\n",
      "    [0. 0. 0. ... 0. 0. 0.]]]]], shape=(1, 35, 35, 3, 15), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(label1)\n",
    "img_dir = '/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k/train/fdd6cabd-240ddcad.jpg'\n",
    "loss = YoloLoss(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([46185.69], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = loss(label1, label2)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
