{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Formatting\n",
    "The Berkeley Deep Drive dataset is surely cool, but we need to filter the enormous amount of info that are given with each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing main packages\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pathlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files preprocessing\n",
    "The main problem is that a 1.5GB JSON file is pretty much untractable, so i decided to split it in one JSON per image, deleting all useless information like lines and drivable areas and saving the new files elsewhere.\n",
    "\n",
    "Other than that, it seems like there are 140 images w/o label. That's pretty strange since i didn't see anyone ever mentioning it on the forums, but for now i will delete them and act like they never existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders path i'll need\n",
    "main_folder = '/home/andrea/AI/ispr_yolo/data/dataset_bdd/labels'\n",
    "json_train_dir = main_folder + '/bdd100k_labels_images_train.json'\n",
    "json_val_dir = main_folder + '/bdd100k_labels_images_validation.json'\n",
    "\n",
    "folder_train = main_folder + '/train_jsons/'\n",
    "folder_train_csv = main_folder + '/train_label_raw/'\n",
    "folder_val = main_folder + '/val_jsons/'\n",
    "folder_val_csv = main_folder + '/val_label_raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New data form\n",
    "And using more useful coordinates to describe the bounding boxes $(x, y, w, h)$ instead of $(x_1, x_2, y_1, y_2)$ and deleting all useless info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to get more meaningful values to describe the bounding boxes\n",
    "def pov_change(x1,x2,y1,y2):\n",
    "    xb = (x1+x2)/(2)\n",
    "    yb = (y1+y2)/(2)\n",
    "    wb = abs(x1-x2)/2\n",
    "    hb = abs(y1-y2)/2\n",
    "    return xb,yb,wb,hb\n",
    "\n",
    "#Loading a JSON file into a Python variable\n",
    "def json_parser(path):\n",
    "    with open(path, 'r') as read_file:\n",
    "        data = json.load(read_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning a JSON file from all the useless information\n",
    "def json_cleaner(data):\n",
    "    # Cleaning timestamps and not so useful attributes\n",
    "    for item in data:\n",
    "        del item['attributes']\n",
    "        del item['timestamp']\n",
    "\n",
    "    # Cleaning drivable area and lanes\n",
    "    for item in data:\n",
    "        storing_indexes = []\n",
    "        for index, i in enumerate(item['labels']):\n",
    "            del i['attributes']\n",
    "            del i['manualShape']\n",
    "            del i['manualAttributes']\n",
    "            if 'box2d' in i:\n",
    "                xb,yb,wb,hb = pov_change(i['box2d']['x1'],i['box2d']['x2'],i['box2d']['y1'],i['box2d']['y2'])\n",
    "                i['box2d']['xb'] = round(xb)\n",
    "                i['box2d']['yb'] = round(yb)\n",
    "                i['box2d']['wb'] = round(wb)\n",
    "                i['box2d']['hb'] = round(hb)\n",
    "                del i['box2d']['x1']\n",
    "                del i['box2d']['x2']\n",
    "                del i['box2d']['y1']\n",
    "                del i['box2d']['y2']\n",
    "            # Checking if anything is corrupted\n",
    "            if not 'poly2d' in i and not 'box2d' in i: print('no box2d?' + str(i['id']))\n",
    "            if 'box3d' in i: print('wtf')\n",
    "                \n",
    "            del i['id']\n",
    "            if i['category'] == 'lane' or i['category'] == 'drivable area':\n",
    "                storing_indexes.append(index)\n",
    "        storing_indexes.sort(reverse=True)\n",
    "        for indexes in storing_indexes:\n",
    "            del item['labels'][indexes]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting labels in single files\n",
    "We're gonna create a json file for every image, with the same name + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing a single JSON into multiple ones\n",
    "def split_data(data,path):\n",
    "    for item in data:\n",
    "        name = item['name']\n",
    "        with open(path + name + '.json', 'w') as file_to_write:\n",
    "            json.dump(item, file_to_write, indent = 4)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update: splitting in raw files\n",
    "It doesn't seem like a good idea to stick with json data format, since there are way more efficient way to store info and load them to tensorflow. The best choice may be TFRecord, but we'll make it simple using raw files.\n",
    "I also decided to encode the category label into one-hot vector and add the objectiveness label, in such a way i get the 1x15 target vector already ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['bus', 'traffic light', 'traffic sign', 'person', 'bike', 'truck', 'motor', 'car', 'train', 'rider']\n",
    "\n",
    "def split_data_csv(data, path):\n",
    "    for item in data:\n",
    "        name = item['name']\n",
    "        line = []\n",
    "        for objects in item['labels']:\n",
    "            one_hot = [int(objects['category'] == x) for x in class_names]\n",
    "            line_to_append = [objects['box2d']['xb'],\n",
    "                    objects['box2d']['yb'], \n",
    "                    objects['box2d']['wb'],\n",
    "                    objects['box2d']['hb'],\n",
    "                    1]\n",
    "            for logic in one_hot: line_to_append.append(logic)\n",
    "            line.append(line_to_append)\n",
    "        array = np.array(line, dtype = 'int16')\n",
    "        array.tofile(path + name + '.rawlabel')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May take a while to complete the code below, be aware!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = False\n",
    "if runtime:\n",
    "    data_train = json_parser(json_val_dir)\n",
    "    data_train = json_cleaner(data_train)\n",
    "    print('Starting...')\n",
    "    split_data_csv(data_train, folder_train_csv)\n",
    "    print('Training data: done')\n",
    "    data_val = json_parser(json_val_dir)\n",
    "    data_val = json_cleaner(data_val)\n",
    "    split_data_csv(data_val, folder_val_csv)\n",
    "    print('Validation data: done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPDATE 2: a single big file\n",
    "Seems like having a lot of small files is hurting performance really bad. It may be worth a try to get a single big dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': '0000f77c-6257be58.jpg', 'labels': [[1141, 172, 16, 39, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1174, 174, 17, 37, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1136, 222, 35, 11, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [50, 62, 50, 61, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [202, 371, 156, 117, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [708, 332, 200, 110, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [51, 67, 51, 66, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]}, {'name': '0000f77c-62c2a288.jpg', 'labels': [[279, 326, 29, 31, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [214, 311, 7, 11, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [931, 292, 6, 6, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [429, 347, 6, 11, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [569, 336, 5, 12, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [662, 331, 5, 15, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]]}, {'name': '0000f77c-cb820c98.jpg', 'labels': [[612, 326, 30, 24, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [710, 315, 13, 16, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [742, 324, 27, 21, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [812, 334, 52, 42, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [849, 347, 48, 47, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [965, 360, 111, 76, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1207, 420, 71, 119, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]}]\n"
     ]
    }
   ],
   "source": [
    "def single_csv(data, path):\n",
    "    big_list=[]\n",
    "    for item in data:\n",
    "        name = item['name']\n",
    "        line = []\n",
    "        for objects in item['labels']:\n",
    "            one_hot = [int(objects['category'] == x) for x in class_names]\n",
    "            line_to_append = [objects['box2d']['xb'],\n",
    "                    objects['box2d']['yb'], \n",
    "                    objects['box2d']['wb'],\n",
    "                    objects['box2d']['hb'],\n",
    "                    1]\n",
    "            for logic in one_hot: line_to_append.append(logic)\n",
    "            line.append(line_to_append)\n",
    "        dict_ = {\n",
    "            'name': name,\n",
    "            'labels': line\n",
    "        }\n",
    "        big_list.append(dict_)\n",
    "    return big_list\n",
    "data_train = json_parser(json_train_dir)\n",
    "data_train = json_cleaner(data_train)\n",
    "data = single_csv(data_train, folder_train_csv)\n",
    "print(data[0:3])\n",
    "import csv\n",
    "with open('myfile.csv', 'w', newline='\\n') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting corrupted images\n",
    "Making sure every image in the train folder has a json file attached to it, otherwise delete the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images w/o label:0\n"
     ]
    }
   ],
   "source": [
    "def detect_missing_labels(delete = False):\n",
    "    counter = 0\n",
    "    main_dir = pathlib.Path('/home/andrea/AI/ispr_yolo/data/dataset_bdd')\n",
    "    img_dir = main_dir.joinpath('images', '100k', 'val').glob('*.jpg')\n",
    "    label_dir = main_dir.joinpath('labels', 'val_label_raw')\n",
    "    for img in img_dir:\n",
    "        img_name = img.name\n",
    "        label_path = label_dir.joinpath(img_name + '.rawlabel')\n",
    "        if not label_path.is_file():\n",
    "            counter = counter + 1\n",
    "            if delete:\n",
    "                img.unlink()\n",
    "                print('deleted')\n",
    "    print('Images w/o label:' + str(counter))\n",
    "    \n",
    "detect_missing_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data Format\n",
    "\n",
    "Here below you can see how data was initially formatted, and how we cleaned it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Setup of the dataset:\n",
      "Data type: <class 'list'>\n",
      "Element of the list: <class 'dict'>\n",
      "Keys of the dictionaries: \n",
      "    name\n",
      "    attributes\n",
      "    timestamp\n",
      "    labels\n",
      "Dict example:\n",
      "    Key: name\n",
      "      Value: b1c66a42-6f7d68ca.jpg\n",
      "    Key: attributes\n",
      "      Value: {'weather': 'overcast', 'scene': 'city street', 'timeofday': 'daytime'}\n",
      "    Key: timestamp\n",
      "      Value: 10000\n",
      "    Key: labels\n",
      "      Value: it is a <class 'list'> made of <class 'dict'>\n",
      "{'category': 'traffic sign', 'attributes': {'occluded': False, 'truncated': False, 'trafficLightColor': 'none'}, 'manualShape': True, 'manualAttributes': True, 'box2d': {'x1': 1000.698742, 'y1': 281.992415, 'x2': 1040.626872, 'y2': 326.91156}, 'id': 0}\n",
      "{'category': 'traffic sign', 'attributes': {'occluded': False, 'truncated': False, 'trafficLightColor': 'none'}, 'manualShape': True, 'manualAttributes': True, 'box2d': {'x1': 214.613695, 'y1': 172.190058, 'x2': 274.505889, 'y2': 229.586743}, 'id': 1}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example function to show the difference between the data before and after the cleaning\n",
    "def showme_data_format(path):\n",
    "    with open(path, 'r') as read_file:\n",
    "        data = json.load(read_file)\n",
    "    print('Data type: ' + str(type(data)))\n",
    "    print('Element of the list: ' + str(type(data[0])))\n",
    "    print('Keys of the dictionaries: ')\n",
    "    for key in data[0]:\n",
    "        print('    ' + str(key))\n",
    "    print('Dict example:')\n",
    "    for key, value in data[0].items():\n",
    "        if key != 'labels':\n",
    "            print('    Key: ' + str(key))\n",
    "            print('      Value: ' + str(value))\n",
    "        else:\n",
    "            print('    Key: ' + str(key))\n",
    "            print('      Value: it is a ' + str(type(value)) + ' made of ' + str(type(value[0])))\n",
    "            for ondex, obj in enumerate(value):\n",
    "                if ondex < 2: print(obj)\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "print('Initial Setup of the dataset:')\n",
    "showme_data_format(main_folder + '/try.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'b1c66a42-6f7d68ca.jpg', 'labels': [{'category': 'traffic sign', 'box2d': {'xb': 1021, 'yb': 304, 'wb': 20, 'hb': 22}}, {'category': 'traffic sign', 'box2d': {'xb': 245, 'yb': 201, 'wb': 30, 'hb': 29}}, {'category': 'traffic sign', 'box2d': {'xb': 814, 'yb': 328, 'wb': 16, 'hb': 14}}, {'category': 'traffic sign', 'box2d': {'xb': 669, 'yb': 309, 'wb': 16, 'hb': 6}}, {'category': 'traffic light', 'box2d': {'xb': 712, 'yb': 320, 'wb': 4, 'hb': 8}}, {'category': 'traffic light', 'box2d': {'xb': 631, 'yb': 306, 'wb': 5, 'hb': 11}}, {'category': 'traffic light', 'box2d': {'xb': 323, 'yb': 298, 'wb': 6, 'hb': 9}}, {'category': 'traffic sign', 'box2d': {'xb': 290, 'yb': 295, 'wb': 19, 'hb': 7}}, {'category': 'traffic sign', 'box2d': {'xb': 226, 'yb': 306, 'wb': 6, 'hb': 6}}, {'category': 'car', 'box2d': {'xb': 244, 'yb': 363, 'wb': 38, 'hb': 25}}, {'category': 'car', 'box2d': {'xb': 89, 'yb': 372, 'wb': 41, 'hb': 28}}, {'category': 'car', 'box2d': {'xb': 297, 'yb': 370, 'wb': 50, 'hb': 26}}, {'category': 'car', 'box2d': {'xb': 26, 'yb': 370, 'wb': 26, 'hb': 33}}, {'category': 'rider', 'box2d': {'xb': 657, 'yb': 368, 'wb': 7, 'hb': 14}}, {'category': 'motor', 'box2d': {'xb': 656, 'yb': 377, 'wb': 7, 'hb': 11}}, {'category': 'traffic light', 'box2d': {'xb': 719, 'yb': 345, 'wb': 7, 'hb': 8}}, {'category': 'car', 'box2d': {'xb': 702, 'yb': 375, 'wb': 19, 'hb': 18}}, {'category': 'car', 'box2d': {'xb': 720, 'yb': 377, 'wb': 14, 'hb': 13}}, {'category': 'car', 'box2d': {'xb': 744, 'yb': 383, 'wb': 17, 'hb': 17}}, {'category': 'car', 'box2d': {'xb': 779, 'yb': 386, 'wb': 30, 'hb': 24}}, {'category': 'car', 'box2d': {'xb': 847, 'yb': 392, 'wb': 59, 'hb': 34}}, {'category': 'car', 'box2d': {'xb': 920, 'yb': 414, 'wb': 40, 'hb': 38}}, {'category': 'car', 'box2d': {'xb': 1074, 'yb': 410, 'wb': 138, 'hb': 74}}, {'category': 'car', 'box2d': {'xb': 1242, 'yb': 473, 'wb': 37, 'hb': 57}}, {'category': 'traffic light', 'box2d': {'xb': 606, 'yb': 347, 'wb': 4, 'hb': 6}}, {'category': 'traffic light', 'box2d': {'xb': 595, 'yb': 335, 'wb': 3, 'hb': 7}}, {'category': 'traffic light', 'box2d': {'xb': 533, 'yb': 337, 'wb': 4, 'hb': 5}}, {'category': 'car', 'box2d': {'xb': 558, 'yb': 362, 'wb': 7, 'hb': 6}}, {'category': 'car', 'box2d': {'xb': 580, 'yb': 361, 'wb': 6, 'hb': 9}}, {'category': 'car', 'box2d': {'xb': 590, 'yb': 367, 'wb': 8, 'hb': 11}}, {'category': 'car', 'box2d': {'xb': 616, 'yb': 369, 'wb': 20, 'hb': 17}}, {'category': 'car', 'box2d': {'xb': 527, 'yb': 362, 'wb': 9, 'hb': 6}}, {'category': 'car', 'box2d': {'xb': 510, 'yb': 364, 'wb': 8, 'hb': 7}}, {'category': 'car', 'box2d': {'xb': 466, 'yb': 363, 'wb': 13, 'hb': 10}}]}, {'name': 'b1c81faa-3df17267.jpg', 'labels': [{'category': 'car', 'box2d': {'xb': 854, 'yb': 296, 'wb': 35, 'hb': 16}}, {'category': 'car', 'box2d': {'xb': 1040, 'yb': 299, 'wb': 13, 'hb': 8}}, {'category': 'traffic sign', 'box2d': {'xb': 1098, 'yb': 250, 'wb': 36, 'hb': 16}}, {'category': 'traffic light', 'box2d': {'xb': 1018, 'yb': 272, 'wb': 13, 'hb': 8}}]}, {'name': 'b1c81faa-c80764c5.jpg', 'labels': [{'category': 'traffic sign', 'box2d': {'xb': 664, 'yb': 157, 'wb': 15, 'hb': 6}}, {'category': 'traffic sign', 'box2d': {'xb': 545, 'yb': 195, 'wb': 43, 'hb': 28}}, {'category': 'traffic sign', 'box2d': {'xb': 633, 'yb': 192, 'wb': 45, 'hb': 32}}, {'category': 'car', 'box2d': {'xb': 480, 'yb': 281, 'wb': 8, 'hb': 6}}, {'category': 'car', 'box2d': {'xb': 513, 'yb': 280, 'wb': 12, 'hb': 8}}, {'category': 'car', 'box2d': {'xb': 541, 'yb': 282, 'wb': 7, 'hb': 6}}, {'category': 'car', 'box2d': {'xb': 569, 'yb': 283, 'wb': 5, 'hb': 4}}, {'category': 'car', 'box2d': {'xb': 587, 'yb': 284, 'wb': 9, 'hb': 4}}, {'category': 'car', 'box2d': {'xb': 721, 'yb': 287, 'wb': 7, 'hb': 5}}, {'category': 'car', 'box2d': {'xb': 708, 'yb': 288, 'wb': 7, 'hb': 6}}, {'category': 'car', 'box2d': {'xb': 683, 'yb': 286, 'wb': 11, 'hb': 7}}, {'category': 'car', 'box2d': {'xb': 641, 'yb': 289, 'wb': 10, 'hb': 7}}, {'category': 'car', 'box2d': {'xb': 629, 'yb': 294, 'wb': 17, 'hb': 13}}, {'category': 'car', 'box2d': {'xb': 403, 'yb': 295, 'wb': 46, 'hb': 31}}]}]\n"
     ]
    }
   ],
   "source": [
    "data = json_parser(main_folder + '/try.json')\n",
    "data_cleaned = json_cleaner(data)\n",
    "print(data_cleaned)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
