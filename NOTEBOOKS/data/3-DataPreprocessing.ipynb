{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "We're gonna create a proper tf.data.Dataset object with an iterator (cause otherwise it won't fit in memory).\n",
    "To do that we need to scale the inputs, both the image and the labels.\n",
    "Since the output of the network is like *13x13x3x(4+1+num_classes)* we also need to format our ground truth into such a matrix first, in order to calculate the loss function (more or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing main packages\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_DIMENSION = 1280\n",
    "SCALE = 1\n",
    "# GRID SIZE\n",
    "SMALL = 40\n",
    "MEDIUM = 80\n",
    "LARGE = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_anchors = tf.constant([(10, 10), (22, 23), (47, 33), (39, 81), (82, 54), (127, 86),\n",
    "                         (118, 168), (194, 130), (257, 221)], tf.float32) / IMG_DIMENSION\n",
    "masks = [[0,1,2],\n",
    "         [3,4,5],\n",
    "         [6,7,8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepocessor object\n",
    "We're gonna define a Preprocessor Object that *grey pad* the image and resize it to be a square, and preprocess the labels accordingly.\n",
    "Note that in input pipelines eager mode is not available even in TF 2.x! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, num_classes = 10, output_dimension = 1280, training = True):\n",
    "        self.num_classes = num_classes\n",
    "        self.output_dimension = output_dimension\n",
    "        self.training = training\n",
    "        \n",
    "    def __call__(self, image_path):\n",
    "        '''\n",
    "        INPUT: the path of the image i want to preprocess\n",
    "        OUTPUTS: a Tensor if training is false\n",
    "                 a Tuple of (1280x1280, (35x35x3x15, 70x70x3x15, 140x140x3x15))\n",
    "                            (Image, Ground Truth)\n",
    "        '''\n",
    "        img = self.load_img(image_path)\n",
    "        label = self.load_label(image_path)\n",
    "        img, label = self.resize_img_n_label(img, label)\n",
    "        \n",
    "        output = (img, (self.preprocess_label_for_one_scale('large', label),\n",
    "              self.preprocess_label_for_one_scale('medium', label),\n",
    "              self.preprocess_label_for_one_scale('small', label)))\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "    def preprocess_label_for_one_scale(self, grid_size, label):        \n",
    "        if grid_size == 'small':\n",
    "            grid_size = SMALL\n",
    "            idx = 0\n",
    "        elif grid_size == 'medium':\n",
    "            grid_size = MEDIUM\n",
    "            idx = 1\n",
    "        elif grid_size == 'large':\n",
    "            grid_size = LARGE\n",
    "            idx = 2\n",
    "        else: raise ValueError('expected small, medium or large')\n",
    "            \n",
    "        #those are the indices in which i'll place the label\n",
    "        cell = tf.cast(label[..., :2]*grid_size,tf.int64)\n",
    "        anc = self.find_best_anchor(label)\n",
    "        mask = tf.equal(anc // 3, idx)\n",
    "        anc = anc % 3\n",
    "        cell = tf.concat([cell, tf.expand_dims(anc, 1)], 1)\n",
    "        cell_filtered = tf.boolean_mask(cell, mask, axis = 0)\n",
    "        label_filtered = tf.boolean_mask(label, mask, axis = 0)\n",
    "        ### getting x,y relative values to cell borders\n",
    "        label_filtered = tf.concat([label_filtered[..., :2]*grid_size - tf.floor(label_filtered[..., :2]*grid_size), label_filtered[..., 2:]], 1)\n",
    "        pro_label = tf.scatter_nd(cell_filtered, label_filtered, [grid_size, grid_size, 3, 15])\n",
    "        \n",
    "        return pro_label\n",
    "\n",
    "    def resize_img_n_label(self, img, label):\n",
    "        img = tf.image.resize_with_pad(img, 1280, 1280)\n",
    "        img = img / 255\n",
    "        \n",
    "        y_shift = (1280-720)/2\n",
    "        new_label = tf.stack([label[..., 0], label[..., 1]+y_shift], 1)\n",
    "        new_label = tf.concat([new_label, label[..., 2:]], 1)\n",
    "        label = tf.concat([new_label[..., 0:4]/IMG_DIMENSION, new_label[..., 4:]], axis = 1)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "    def find_best_anchor(self, bb, anchors = yolo_anchors):\n",
    "        ## assuming bb is like [x,y,w,h]\n",
    "        bb = bb[..., 2:4]\n",
    "        bb = tf.expand_dims(bb, 1)\n",
    "        ## we can just assume all anchors and the ground truth box share the same centroid. And with this assumption\n",
    "        ## the degree of matching would be the overlapping area, which can be calculated by min width * min height.\n",
    "        intersection = tf.math.minimum(anchors, bb)\n",
    "        intersection = intersection[..., 0] * intersection[..., 1]\n",
    "        union = anchors[..., 0] * anchors[..., 1] + bb[..., 0] * bb[..., 1] - intersection\n",
    "        broadcast_IoU = intersection/union\n",
    "        best_one = tf.math.argmax(broadcast_IoU, 1)\n",
    "        \n",
    "        return best_one\n",
    "\n",
    "############## Loading images and labels\n",
    "    \n",
    "    def load_img(self, img_path):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3) #(720, 1280, 3)\n",
    "        return img\n",
    "    \n",
    "    def load_label(self, img_path):\n",
    "        # Get the right path\n",
    "        label_path = self.get_label_path(img_path)\n",
    "        # Load the file and shape it\n",
    "        label = tf.io.read_file(label_path)\n",
    "        label = tf.io.decode_raw(label, tf.int16)\n",
    "        label = tf.cast(label,tf.float32)\n",
    "        label = tf.reshape(label, [-1, 15])\n",
    "        return label\n",
    "    \n",
    "    def get_label_path(self, img_path):\n",
    "        parts = tf.strings.split(img_path, sep = '/images/100k/train/')\n",
    "        label_path = tf.strings.join([parts[0], '/labels/train_label_raw/', parts[1], '.rawlabel'])\n",
    "        return label_path\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset\n",
    "Now that we have a fully TF mapping function without any loop we're ready to create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(1280, 1280, 3), dtype=float32)\n",
      "[[[0.458823532 0.505882382 0.490196079]\n",
      "  [0.498039216 0.556862772 0.53725493]\n",
      "  [0.447058827 0.494117647 0.478431374]]\n",
      "\n",
      " [[0.56078434 0.607843161 0.592156887]\n",
      "  [0.509803951 0.556862772 0.541176498]\n",
      "  [0.360784322 0.407843143 0.392156869]]\n",
      "\n",
      " [[0.568627477 0.615686297 0.6]\n",
      "  [0.494117647 0.541176498 0.525490224]\n",
      "  [0.352941185 0.4 0.384313732]]]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(global_path, batch = 32):\n",
    "    dataset = tf.data.Dataset.list_files([global_path])\n",
    "    mapping_func = Preprocess()\n",
    "    dataset = dataset.map(mapping_func)\n",
    "    if batch == 1:\n",
    "        return dataset.prefetch(1)\n",
    "    dataset = dataset.batch(32).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "# imgdir = '/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k' + '/train/*.jpg'\n",
    "# dataset = tf.data.Dataset.list_files([imgdir])\n",
    "# mapping_func = Preprocess()\n",
    "# dataset = dataset.map(mapping_func)\n",
    "# dataset = dataset.batch(32).prefetch(1)\n",
    "\n",
    "# val_size = int(7000)\n",
    "# train_ds = dataset.skip(val_size)\n",
    "# val_ds = dataset.take(val_size)\n",
    "\n",
    "# print(train_ds)\n",
    "# print(val_ds)\n",
    "def generate_two_label_example(batch = False):\n",
    "    dataset = create_dataset('/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k' + '/train/*.jpg', batch=1)\n",
    "    labels = []\n",
    "    for item in dataset.take(1):\n",
    "        img, label = item\n",
    "#         labels.append(label)\n",
    "#         print(label[2])\n",
    "        print(img)\n",
    "        tf.print(img[600:603,600:603,...])\n",
    "generate_two_label_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw label:\n",
      "[[402 212 12 ... 0 0 0]\n",
      " [862 169 22 ... 0 0 0]\n",
      " [999 169 14 ... 0 0 0]\n",
      " ...\n",
      " [112 326 112 ... 1 0 0]\n",
      " [1126 404 153 ... 1 0 0]\n",
      " [573 196 131 ... 0 0 0]]\n",
      "\n",
      " indices after padding\n",
      "[[12 15 0]\n",
      " [26 14 0]\n",
      " [31 14 1]\n",
      " ...\n",
      " [7 16 1]\n",
      " [13 16 0]\n",
      " [34 17 2]]\n",
      "\n",
      " actual values in target\n",
      "[[0.5625 0.375 0.009375 ... 0 0 0]\n",
      " [0.9375 0.03125 0.0171875 ... 0 0 0]\n",
      " [0.21875 0.03125 0.0109375 ... 0 0 0]\n",
      " ...\n",
      " [0.625 0.6875 0.0203125 ... 1 0 0]\n",
      " [0.6875 0.78125 0.00625 ... 1 0 0]\n",
      " [0.15625 0.375 0.0328125 ... 1 0 0]]\n",
      "[0.21875 0.03125 0.0109375 0.025 1 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "image_path = '/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k/train/5823b731-7716da84.jpg'\n",
    "prep = Preprocess()\n",
    "img = prep.load_img(image_path)\n",
    "label = prep.load_label(image_path)\n",
    "print('raw label:')\n",
    "tf.print(label)\n",
    "img, label = prep.resize_img_n_label(img, label)\n",
    "cell = tf.cast(label[..., :2]*40,tf.int64)\n",
    "\n",
    "anc = prep.find_best_anchor(label)\n",
    "\n",
    "mask = tf.equal(anc // 3, 0)\n",
    "anc = anc % 3\n",
    "\n",
    "cell = tf.concat([cell, tf.expand_dims(anc, 1)], 1)\n",
    "\n",
    "cell_filtered = tf.boolean_mask(cell, mask, axis = 0)\n",
    "print('\\n indices after padding')\n",
    "tf.print(cell_filtered)\n",
    "label_filtered = tf.boolean_mask(label, mask, axis = 0)\n",
    "label_filtered = tf.concat([label_filtered[..., :2]*40 - tf.floor(label_filtered[..., :2]*40), label_filtered[..., 2:]], 1)\n",
    "print('\\n actual values in target')\n",
    "tf.print(label_filtered)\n",
    "pro_label = tf.scatter_nd(cell_filtered, label_filtered, [40, 40, 3, 15])\n",
    "tf.print(pro_label[31,14,1, ...], summarize = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
