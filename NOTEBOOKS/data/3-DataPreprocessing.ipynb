{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "We're gonna create a proper tf.data.Dataset object with an iterator (cause otherwise it won't fit in memory).\n",
    "To do that we need to scale the inputs, both the image and the labels.\n",
    "Since the output of the network is like *13x13x3x(4+1+num_classes)* we also need to format our ground truth into such a matrix first, in order to calculate the loss function (more or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing main packages\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_DIMENSION = 1280\n",
    "SCALE = 1\n",
    "# GRID SIZE\n",
    "COARSE = 40\n",
    "MEDIUM = 80\n",
    "DENSE = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:2 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c4da18310c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m yolo_anchors = tf.constant([(19, 19), (43, 46), (94, 66), (77, 163), (163, 107), (253, 172), (237, 337),\n\u001b[0;32m----> 2\u001b[0;31m                             (388, 260), (514, 441)], tf.float32) / IMG_DIMENSION\n\u001b[0m\u001b[1;32m      3\u001b[0m masks = [[0,1,2],\n\u001b[1;32m      4\u001b[0m          \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          [6,7,8]]\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_tfrt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextOptionsSetTfrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_tfrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:2 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "yolo_anchors = tf.constant([(19, 19), (43, 46), (94, 66), (77, 163), (163, 107), (253, 172), (237, 337),\n",
    "                            (388, 260), (514, 441)], tf.float32) / IMG_DIMENSION\n",
    "masks = [[0,1,2],\n",
    "         [3,4,5],\n",
    "         [6,7,8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepocessor object\n",
    "We're gonna define a Preprocessor Object that *grey pad* the image and resize it to be a square, and preprocess the labels accordingly.\n",
    "Note that in input pipelines eager mode is not available even in TF 2.x! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, num_classes = 10, output_dimension = 1280, training = True, validation = False, augmentation = False):\n",
    "        self.num_classes = num_classes\n",
    "        self.output_dimension = output_dimension\n",
    "        self.training = training\n",
    "        self.validation = validation\n",
    "        self.augmentation = augmentation\n",
    "        \n",
    "    def __call__(self, image_path):\n",
    "        '''\n",
    "        INPUT: the path of the image i want to preprocess\n",
    "        OUTPUTS: a Tensor if training is false\n",
    "                 a Tuple of (1280x1280, (35x35x3x15, 70x70x3x15, 140x140x3x15))\n",
    "                            (Image, Ground Truth)\n",
    "        '''\n",
    "        img = self.load_img(image_path)\n",
    "        label = self.load_label(image_path)\n",
    "        img, label = self.resize_img_n_label(img, label)\n",
    "        \n",
    "        output = (img, (self.preprocess_label_for_one_scale('dense', label),\n",
    "              self.preprocess_label_for_one_scale('medium', label),\n",
    "              self.preprocess_label_for_one_scale('coarse', label)))\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def augmentation(self, img, label):\n",
    "        flipped_img = tf.image.flip_left_right(img)\n",
    "        flipped_label = tf.stack(1280 - label[..., 0], label[..., 1:] )\n",
    "        return flipped_img, flipped_label\n",
    "        \n",
    "        \n",
    "    def preprocess_label_for_one_scale(self, grid_size, label):        \n",
    "        if grid_size == 'dense':\n",
    "            grid_size = DENSE\n",
    "            idx = 0\n",
    "        elif grid_size == 'medium':\n",
    "            grid_size = MEDIUM\n",
    "            idx = 1\n",
    "        elif grid_size == 'coarse':\n",
    "            grid_size = COARSE\n",
    "            idx = 2\n",
    "        else: raise ValueError('expected small, medium or large')\n",
    "            \n",
    "        #those are the indices in which i'll place the label\n",
    "        cell = tf.cast(label[..., :2]*grid_size,tf.int64)\n",
    "        cell_x = cell[..., 0]\n",
    "        cell_y = cell[..., 1]\n",
    "        cell = tf.stack([cell_y, cell_x], axis = -1)\n",
    "        anc = self.find_best_anchor(label)\n",
    "        mask = tf.equal(anc // 3, idx)\n",
    "        anc = anc % 3\n",
    "        cell = tf.concat([cell, tf.expand_dims(anc, 1)], 1)\n",
    "        cell_filtered = tf.boolean_mask(cell, mask, axis = 0)\n",
    "        label_filtered = tf.boolean_mask(label, mask, axis = 0)\n",
    "        ### getting x,y relative values to cell borders\n",
    "        label_filtered = tf.concat([label_filtered[..., :2]*grid_size - tf.floor(label_filtered[..., :2]*grid_size), label_filtered[..., 2:]], 1)\n",
    "        pro_label = tf.scatter_nd(cell_filtered, label_filtered, [grid_size, grid_size, 3, 15])\n",
    "        \n",
    "        return pro_label\n",
    "\n",
    "    def resize_img_n_label(self, img, label):\n",
    "        img = tf.image.resize_with_pad(img, 1280, 1280)\n",
    "        img = img / 255\n",
    "        \n",
    "        y_shift = (1280-720)/2\n",
    "        new_label = tf.stack([label[..., 0], label[..., 1]+y_shift], 1)\n",
    "        new_label = tf.concat([new_label, label[..., 2:]], 1)\n",
    "        label = tf.concat([new_label[..., 0:4]/IMG_DIMENSION, new_label[..., 4:]], axis = 1)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "    def find_best_anchor(self, bb, anchors = yolo_anchors):\n",
    "        ## assuming bb is like [x,y,w,h]\n",
    "        bb = bb[..., 2:4]\n",
    "        bb = tf.expand_dims(bb, 1)\n",
    "        ## we can just assume all anchors and the ground truth box share the same centroid. And with this assumption\n",
    "        ## the degree of matching would be the overlapping area, which can be calculated by min width * min height.\n",
    "        intersection = tf.math.minimum(anchors, bb)\n",
    "        intersection = intersection[..., 0] * intersection[..., 1]\n",
    "        union = anchors[..., 0] * anchors[..., 1] + bb[..., 0] * bb[..., 1] - intersection\n",
    "        broadcast_IoU = intersection/union\n",
    "        best_one = tf.math.argmax(broadcast_IoU, 1)\n",
    "        \n",
    "        return best_one\n",
    "\n",
    "############## Loading images and labels\n",
    "    \n",
    "    def load_img(self, img_path):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3) #(720, 1280, 3)\n",
    "        return img\n",
    "    \n",
    "    def load_label(self, img_path):\n",
    "        # Get the right path\n",
    "        label_path = self.get_label_path(img_path)\n",
    "        # Load the file and shape it\n",
    "        label = tf.io.read_file(label_path)\n",
    "        label = tf.io.decode_raw(label, tf.int16)\n",
    "        label = tf.cast(label,tf.float32)\n",
    "        label = tf.reshape(label, [-1, 15])\n",
    "        return label\n",
    "    \n",
    "    def get_label_path(self, img_path):\n",
    "        if not self.validation:\n",
    "            parts = tf.strings.split(img_path, sep = '/images/100k/train/')\n",
    "            label_path = tf.strings.join([parts[0], '/labels/train_label_raw/', parts[1], '.rawlabel'])\n",
    "        else:\n",
    "            parts = tf.strings.split(img_path, sep = '/images/100k/val/')\n",
    "            label_path = tf.strings.join([parts[0], '/labels/val_label_raw/', parts[1], '.rawlabel'])\n",
    "        return label_path\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset\n",
    "Now that we have a fully TF mapping function without any loop we're ready to create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(global_path, batch = 32):\n",
    "    dataset = tf.data.Dataset.list_files([global_path])\n",
    "    mapping_func = Preprocess()\n",
    "    dataset = dataset.map(mapping_func)\n",
    "    if batch == 1:\n",
    "        return dataset.prefetch(1)\n",
    "    dataset = dataset.batch(32).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "# imgdir = '/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k' + '/train/*.jpg'\n",
    "# dataset = tf.data.Dataset.list_files([imgdir])\n",
    "# mapping_func = Preprocess()\n",
    "# dataset = dataset.map(mapping_func)\n",
    "# dataset = dataset.batch(32).prefetch(1)\n",
    "\n",
    "# val_size = int(7000)\n",
    "# train_ds = dataset.skip(val_size)\n",
    "# val_ds = dataset.take(val_size)\n",
    "\n",
    "# print(train_ds)\n",
    "# print(val_ds)\n",
    "def generate_two_label_example(batch = False):\n",
    "    dataset = create_dataset('/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k' + '/train/*.jpg', batch=1)\n",
    "    labels = []\n",
    "    for item in dataset.take(1):\n",
    "        img, label = item\n",
    "#         labels.append(label)\n",
    "#         print(label[2])\n",
    "        print(img)\n",
    "        tf.print(img[600:603,600:603,...])\n",
    "generate_two_label_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-56c893b417aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k/train/5823b731-7716da84.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw label:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "image_path = '/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k/train/5823b731-7716da84.jpg'\n",
    "prep = Preprocess()\n",
    "img = prep.load_img(image_path)\n",
    "label = prep.load_label(image_path)\n",
    "print('raw label:')\n",
    "tf.print(label, summarize=-1)\n",
    "imgf, labelf = prep.augmentation(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2bedc04c0517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/andrea/AI/ispr_yolo/data/dataset_bdd/images/100k/train/5823b731-7716da84.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw label:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "img, label = prep.resize_img_n_label(img, label)\n",
    "print('resized label:')\n",
    "tf.print(label, summarize=-1)\n",
    "cell = tf.cast(label[..., :2]*40,tf.int64)\n",
    "print('\\n CELL indx')\n",
    "tf.print(cell)\n",
    "cell_x = cell[..., 0]\n",
    "cell_y = cell[..., 1]\n",
    "cell = tf.stack([cell_y, cell_x], axis = -1)\n",
    "tf.print(cell)\n",
    "\n",
    "anc = prep.find_best_anchor(label)\n",
    "\n",
    "mask = tf.equal(anc // 3, 2)\n",
    "anc = anc % 3\n",
    "\n",
    "cell = tf.concat([cell, tf.expand_dims(anc, 1)], 1)\n",
    "\n",
    "cell_filtered = tf.boolean_mask(cell, mask, axis = 0)\n",
    "print('\\n indices after padding')\n",
    "tf.print(cell_filtered)\n",
    "label_filtered = tf.boolean_mask(label, mask, axis = 0)\n",
    "label_filtered = tf.concat([label_filtered[..., :2]*40 - tf.floor(label_filtered[..., :2]*40), label_filtered[..., 2:]], 1)\n",
    "print('\\n actual values in target')\n",
    "tf.print(label_filtered)\n",
    "print('\\n')\n",
    "pro_label = tf.scatter_nd(cell_filtered, label_filtered, [40, 40, 3, 15])\n",
    "tf.print(pro_label[17,14,0, ...], summarize = -1)\n",
    "\n",
    "img, label = prep(image_path)\n",
    "tf.print(label[2][17,14,0, ...])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
